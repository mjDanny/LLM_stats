{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7df8f516"
      },
      "source": [
        "\n",
        "### Цель работы\n",
        "\n",
        "В данном ноутбуке используется LangChain и OpenAI для анализа запросов и оценки их времени выполнения.\n",
        "Мы создадим функцию для трассировки и валидации ответов, получаемых от LLM (Large Language Models),\n",
        "и протестируем производительность модели на простом примере.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dogNLo78NHXl",
        "outputId": "f9f87b01-1e82-4cab-e609-c6c098be56d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting openai\n",
            "  Downloading openai-1.45.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.34)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.4.0,>=0.3.0 (from langchain)\n",
            "  Downloading langchain_core-0.3.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.120-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.0->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.3)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain-0.3.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.0-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.45.0-py3-none-any.whl (374 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.1/374.1 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.0-py3-none-any.whl (405 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.1/405.1 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.120-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.8/289.8 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
            "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: tenacity, python-dotenv, orjson, mypy-extensions, marshmallow, jsonpointer, jiter, h11, faiss-cpu, typing-inspect, tiktoken, jsonpatch, httpcore, pydantic-settings, httpx, dataclasses-json, openai, langsmith, langchain-core, langchain-text-splitters, langchain, langchain_community\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed dataclasses-json-0.6.7 faiss-cpu-1.8.0.post1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.0 langchain-core-0.3.0 langchain-text-splitters-0.3.0 langchain_community-0.3.0 langsmith-0.1.120 marshmallow-3.22.0 mypy-extensions-1.0.0 openai-1.45.0 orjson-3.10.7 pydantic-settings-2.5.2 python-dotenv-1.0.1 tenacity-8.5.0 tiktoken-0.7.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain_community openai faiss-cpu tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79713012"
      },
      "source": [
        "\n",
        "### Установка необходимых библиотек\n",
        "\n",
        "Для корректной работы ноутбука необходимо установить несколько библиотек: `langchain`, `openai`, `faiss-cpu`, и другие.\n",
        "Они будут использованы для генерации ответов и обработки запросов к языковым моделям.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KW4d8idQSkAV"
      },
      "outputs": [],
      "source": [
        "# Импорт необходимых библиотек для работы с LLM и FAISS\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema import SystemMessage, HumanMessage\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "import logging\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Настраиваем логирование для вывода в консоль (Colab)\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', handlers=[logging.StreamHandler()])\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Устанавливаем ключ API для OpenAI\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7ZhzuV1Skzb",
        "outputId": "23365200-50d8-4e37-986b-f2d91d116a0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-0626133f1975>:5: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  llm = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n"
          ]
        }
      ],
      "source": [
        "# Инициализация модели GPT-3.5-turbo для работы с чатами\n",
        "def initialize_llm():\n",
        "    logger.info(\"Настраиваем модель ChatOpenAI с GPT-3.5-turbo...\")\n",
        "    try:\n",
        "        llm = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "        logger.info(\"Chat LLM успешно настроена.\")\n",
        "        return llm\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Ошибка при инициализации модели: {e}\")\n",
        "        raise e\n",
        "\n",
        "llm = initialize_llm()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFpRSrzLSll3"
      },
      "outputs": [],
      "source": [
        "# Создание шаблона для диалога с нейросотрудником\n",
        "def create_chat_prompt():\n",
        "    logger.info(\"Создаем шаблон для вопросов...\")\n",
        "    try:\n",
        "        chat_prompt = ChatPromptTemplate.from_messages([\n",
        "            SystemMessage(content=\"Ты эксперт по машинному обучению.\"),\n",
        "            HumanMessage(content=\"{question}\")\n",
        "        ])\n",
        "        logger.info(\"Шаблон для вопросов успешно создан.\")\n",
        "        return chat_prompt\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Ошибка при создании шаблона: {e}\")\n",
        "        raise e\n",
        "\n",
        "chat_prompt = create_chat_prompt()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmBRfyW6SmXf",
        "outputId": "65898dd3-1e84-4c21-ab17-569e6bc7c40f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-9fa5ee9da349>:22: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  embeddings = OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n"
          ]
        }
      ],
      "source": [
        "# Инициализация FAISS и подготовка базы знаний\n",
        "def initialize_faiss(embeddings, documents):\n",
        "    logger.info(\"Инициализируем FAISS и загружаем базу знаний...\")\n",
        "    try:\n",
        "        # Преобразуем текст документов в эмбеддинги\n",
        "        texts = [doc['text'] for doc in documents]\n",
        "        ids = [doc['id'] for doc in documents]\n",
        "\n",
        "        # Создаем векторное хранилище с использованием FAISS\n",
        "        knowledge_base = FAISS.from_texts(texts, embeddings, metadatas=[{\"id\": doc[\"id\"]} for doc in documents])\n",
        "        logger.info(\"Документы успешно загружены в FAISS.\")\n",
        "        return knowledge_base\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Ошибка при инициализации FAISS: {e}\")\n",
        "        raise e\n",
        "\n",
        "documents = [\n",
        "    {\"text\": \"Документация по Scikit-Learn\", \"id\": \"1\"},\n",
        "    {\"text\": \"Туториал по нейронным сетям\", \"id\": \"2\"}\n",
        "]\n",
        "\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "knowledge_base = initialize_faiss(embeddings, documents)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X24gJ7M8Snxf",
        "outputId": "2d0f1461-2dd0-488d-abe5-9a9fcf2ae35c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-6df8b574c67d>:8: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use invoke instead.\n",
            "  response = llm(messages=prompt)\n"
          ]
        }
      ],
      "source": [
        "# Функция для трассировки запроса и ответа модели\n",
        "def trace_query(query, llm, chat_prompt):\n",
        "    logger.info(f\"Трассировка запроса: '{query}'\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    try:\n",
        "        prompt = chat_prompt.format_prompt(question=query).to_messages()\n",
        "        response = llm(messages=prompt)\n",
        "        elapsed_time = time.time() - start_time\n",
        "        logger.info(f\"Запрос успешно обработан за {elapsed_time:.2f} секунд. Ответ модели: {response}\")\n",
        "        return response, elapsed_time\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Ошибка при обработке запроса: {e}\")\n",
        "        raise e\n",
        "\n",
        "# Пример трассировки запроса\n",
        "query = \"Что такое машинное обучение?\"\n",
        "response, time_taken = trace_query(query, llm, chat_prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzRPlwLLSoyk"
      },
      "outputs": [],
      "source": [
        "# Функция для валидации ответа на основе знаний\n",
        "def validate_response(query, response, knowledge_base):\n",
        "    logger.info(f\"Валидация ответа для запроса: '{query}'\")\n",
        "    try:\n",
        "        relevant_docs = knowledge_base.search(query, search_type=\"similarity\")\n",
        "        if not relevant_docs:\n",
        "            logger.warning(\"Не найдено релевантных документов в базе знаний. Возможна галлюцинация.\")\n",
        "            return False\n",
        "\n",
        "        logger.info(f\"Найдено {len(relevant_docs)} релевантных документов.\")\n",
        "        for doc in relevant_docs:\n",
        "            logger.info(f\"Документ ID: {doc.metadata['id']}, Текст: {doc.page_content}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Ошибка при валидации ответа: {e}\")\n",
        "        return False\n",
        "\n",
        "# Пример валидации ответа\n",
        "is_valid = validate_response(query, response, knowledge_base)\n",
        "if not is_valid:\n",
        "    logger.error(\"Ответ не прошел валидацию.\")\n",
        "else:\n",
        "    logger.info(\"Ответ успешно прошел валидацию.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMI20RtFSpsJ",
        "outputId": "98fefea0-06ce-4070-9f68-633a60123292"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Привет! Чем могу помочь?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 31, 'total_tokens': 45, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-74a59c96-eb34-4474-8fff-688e22f6de86-0')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Основная функция для обработки запросов и валидации\n",
        "def process_query(query, llm, chat_prompt, knowledge_base):\n",
        "    logger.info(f\"Начинаем обработку запроса: '{query}'\")\n",
        "    response, time_taken = trace_query(query, llm, chat_prompt)\n",
        "\n",
        "    if not validate_response(query, response, knowledge_base):\n",
        "        logger.error(f\"Галлюцинация обнаружена при обработке запроса '{query}'\")\n",
        "    else:\n",
        "        logger.info(f\"Запрос '{query}' успешно обработан и валидирован.\")\n",
        "\n",
        "    return response\n",
        "\n",
        "# Пример обработки запроса\n",
        "query = \"Что такое нейронные сети?\"\n",
        "process_query(query, llm, chat_prompt, knowledge_base)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLDbRQIXSqrW"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Функция для анализа производительности запроса\n",
        "# Аргументы:\n",
        "# query: строка, содержащая текст запроса\n",
        "# llm: модель языкового моделирования, используемая для генерации ответа\n",
        "# chat_prompt: подсказка для чат-бота, если она используется\n",
        "# knowledge_base: база знаний для валидации ответов\n",
        "def analyze_performance(query, llm, chat_prompt, knowledge_base):\n",
        "    # Логирование начала анализа времени\n",
        "    logger.info(\"Анализируем время выполнения запросов...\")\n",
        "\n",
        "    # Запускаем трассировку выполнения запроса\n",
        "    response, time_taken = trace_query(query, llm, chat_prompt)\n",
        "\n",
        "    # Выводим информацию о времени выполнения\n",
        "    logger.info(f\"Время выполнения запроса: {time_taken:.2f} секунд.\")\n",
        "\n",
        "    # Проверяем корректность полученного ответа с базой знаний\n",
        "    if validate_response(query, response, knowledge_base):\n",
        "        logger.info(f\"Запрос '{query}' прошел валидацию и успешно обработан.\")\n",
        "    else:\n",
        "        logger.error(f\"Ошибка: Запрос '{query}' не прошел валидацию.\")\n",
        "\n",
        "    # Возвращаем время выполнения\n",
        "    return time_taken\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9e6da36"
      },
      "source": [
        "\n",
        "### Пример использования функции\n",
        "\n",
        "После настройки окружения, вы можете протестировать производительность модели с помощью запроса.\n",
        "Ниже приведён пример запроса о градиентном спуске и оценка времени выполнения запроса.\n",
        "```python\n",
        "query = \"Расскажи про градиентный спуск\"\n",
        "time_taken = analyze_performance(query, llm, chat_prompt, knowledge_base)\n",
        "print(f\"Время выполнения запроса: {time_taken:.2f} секунд.\")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc45eec8"
      },
      "source": [
        "\n",
        "### Вывод\n",
        "\n",
        "Данный ноутбук позволяет трассировать запросы и проверять время их выполнения с использованием языковых моделей.\n",
        "На основе результатов можно оптимизировать производительность модели, а также валидировать корректность ответов.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}